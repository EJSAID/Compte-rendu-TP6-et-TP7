{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBY1Vdsp00eN"
   },
   "source": [
    "<center><h1> Série de Travaux Pratiques N° 7 - Machine Learning </h1></center>\n",
    "<center><h2> K-Nearest Neighbor and Decision Tree</h2></center>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OT_v-xSH8NW"
   },
   "source": [
    "Pour ce TP, on utilisera le **dataset IRIS**. Ce dernier est une base de données regroupant les caractéristiques de **trois espèces de fleurs d’Iris, à savoir Setosa, Versicolour et Virginica**. Chaque ligne de ce jeu de données est une observation des caractéristiques d’une fleur d’Iris. Ce dataset décrit les espèces d’Iris par quatre propriétés : longueur et largeur de sépales ainsi que longueur et largeur de pétales. La base de données comporte 150 observations (50 observations par espèce)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xIqBKf-_MK9"
   },
   "source": [
    "# **Partie I : K-Nearest Neighbor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fG-mqDhouw_G"
   },
   "source": [
    "# **Questions :**\n",
    "\n",
    "1- Importer les packages nécessaires\n",
    "\n",
    "2- Lire l'ensemble de données dans le dataframe pandas\n",
    "\n",
    "3- Afficher et explorer l'ensemble de données \"**iris.csv**\"\n",
    "\n",
    "4- Extraire les variables d'entrée X\n",
    "\n",
    "5- Extraire les variables de sortie y\n",
    "\n",
    "6- Diviser le dataset en Train / Test\n",
    "\n",
    "7- Mise à l'échelle des fonctionnalités avec Transform()\n",
    "\n",
    "8- Définir votre modèle **KNN**\n",
    "\n",
    "9- Entraîner le modèle\n",
    "\n",
    "10- Prédiction sur l'ensemble de test\n",
    "\n",
    "11- Évaluation du modèle à l'aide de métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ab1P8GZVw4gj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal.length  sepal.width  petal.length  petal.width variety\n",
      "0           5.1          3.5           1.4          0.2  Setosa\n",
      "1           4.9          3.0           1.4          0.2  Setosa\n",
      "2           4.7          3.2           1.3          0.2  Setosa\n",
      "3           4.6          3.1           1.5          0.2  Setosa\n",
      "4           5.0          3.6           1.4          0.2  Setosa\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal.length  150 non-null    float64\n",
      " 1   sepal.width   150 non-null    float64\n",
      " 2   petal.length  150 non-null    float64\n",
      " 3   petal.width   150 non-null    float64\n",
      " 4   variety       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n",
      "       sepal.length  sepal.width  petal.length  petal.width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.057333      3.758000     1.199333\n",
      "std        0.828066     0.435866      1.765298     0.762238\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n",
      "(120, 4) (30, 4) (120,) (30,)\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Setosa       1.00      1.00      1.00        10\n",
      "  Versicolor       1.00      1.00      1.00         9\n",
      "   Virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Étape 1 : Importer les packages nécessaires\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Étape 2 : Lire l'ensemble de données dans le dataframe pandas\n",
    "data = pd.read_csv('iris.csv')\n",
    "\n",
    "# Étape 3 : Afficher et explorer l'ensemble de données \"iris.csv\"\n",
    "print(data.head())  # Afficher les 5 premières lignes du jeu de données\n",
    "print(data.info())  # Informations sur les types de données et les valeurs manquantes\n",
    "print(data.describe())  # Statistiques descriptives des colonnes numériques\n",
    "\n",
    "# Étape 4 : Extraire les variables d'entrée X\n",
    "X = data.drop('variety', axis=1)\n",
    "\n",
    "# Étape 5 : Extraire les variables de sortie y\n",
    "y = data['variety']\n",
    "\n",
    "# Étape 6 : Diviser le dataset en Train / Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)  # Afficher les dimensions des ensembles\n",
    "\n",
    "# Étape 7 : Mise à l'échelle des fonctionnalités avec Transform()\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Étape 8 : Définir votre modèle KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Étape 9 : Entraîner le modèle\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Étape 10 : Prédiction sur l'ensemble de test\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Étape 11 : Évaluation du modèle à l'aide de métriques\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRAn-qhBwqgp"
   },
   "source": [
    "# **Partie II : Decision Trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UU1ELn91wg2R"
   },
   "source": [
    "# **Questions :**\n",
    "\n",
    "1- Importer les packages nécessaires\n",
    "\n",
    "2- Lire l'ensemble de données dans le dataframe pandas\n",
    "\n",
    "3- Afficher et explorer l'ensemble de données \"**iris.csv**\"\n",
    "\n",
    "4- Extraire les variables d'entrée X\n",
    "\n",
    "5- Extraire les variables de sortie y\n",
    "\n",
    "6- Diviser le dataset en Train / Test\n",
    "\n",
    "7- Mise à l'échelle des fonctionnalités avec Transform()\n",
    "\n",
    "8- Définir votre modèle **Decision Tree**\n",
    "\n",
    "9- Entraîner le modèle\n",
    "\n",
    "10- Prédiction sur l'ensemble de test\n",
    "\n",
    "11- Évaluation du modèle à l'aide de métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EfkJv-sMxI-c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal.length  sepal.width  petal.length  petal.width variety\n",
      "0           5.1          3.5           1.4          0.2  Setosa\n",
      "1           4.9          3.0           1.4          0.2  Setosa\n",
      "2           4.7          3.2           1.3          0.2  Setosa\n",
      "3           4.6          3.1           1.5          0.2  Setosa\n",
      "4           5.0          3.6           1.4          0.2  Setosa\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal.length  150 non-null    float64\n",
      " 1   sepal.width   150 non-null    float64\n",
      " 2   petal.length  150 non-null    float64\n",
      " 3   petal.width   150 non-null    float64\n",
      " 4   variety       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n",
      "       sepal.length  sepal.width  petal.length  petal.width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.057333      3.758000     1.199333\n",
      "std        0.828066     0.435866      1.765298     0.762238\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n",
      "(120, 4) (30, 4) (120,) (30,)\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Setosa       1.00      1.00      1.00        10\n",
      "  Versicolor       1.00      1.00      1.00         9\n",
      "   Virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Étape 1 : Importer les packages nécessaires\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Étape 2 : Lire l'ensemble de données dans le dataframe pandas\n",
    "data = pd.read_csv('iris.csv')\n",
    "\n",
    "# Étape 3 : Afficher et explorer l'ensemble de données \"iris.csv\"\n",
    "print(data.head())  # Afficher les 5 premières lignes du jeu de données\n",
    "print(data.info())  # Informations sur les types de données et les valeurs manquantes\n",
    "print(data.describe())  # Statistiques descriptives des colonnes numériques\n",
    "\n",
    "# Étape 4 : Extraire les variables d'entrée X\n",
    "X = data.drop('variety', axis=1)\n",
    "\n",
    "# Étape 5 : Extraire les variables de sortie y\n",
    "y = data['variety']\n",
    "\n",
    "# Étape 6 : Diviser le dataset en Train / Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)  # Afficher les dimensions des ensembles\n",
    "\n",
    "# Étape 7 : Mise à l'échelle des fonctionnalités avec Transform()\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Étape 8 : Définir votre modèle Decision Tree\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Étape 9 : Entraîner le modèle\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Étape 10 : Prédiction sur l'ensemble de test\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Étape 11 : Évaluation du modèle à l'aide de métriques\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
