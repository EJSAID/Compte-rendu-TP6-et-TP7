{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBY1Vdsp00eN"
   },
   "source": [
    "<center><h1> Corréction Série de Travaux Pratiques N° 6 - Machine Learning </h1></center>\n",
    "<center><h2> Regression Logistique</h2></center>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xIqBKf-_MK9"
   },
   "source": [
    "# **Partie I : Regression Logistique**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OT_v-xSH8NW"
   },
   "source": [
    "Vous trouverez ci-joint un exemple d'utilisation d'algorithme de regréssion logistique avec les quatres étapes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhmrQYpLAkeD"
   },
   "outputs": [],
   "source": [
    "# Step 1: Import packages, functions\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Step 2: Get data\n",
    "x = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Step 3: Create a model and train it\n",
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0, max_iter=100)\n",
    "model.fit(x, y)\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "p_pred = model.predict_proba(x)\n",
    "y_pred = model.predict(x)\n",
    "score_ = model.score(x, y)\n",
    "conf_m = confusion_matrix(y, y_pred)\n",
    "report = classification_report(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jl6j49CVBPZy",
    "outputId": "1fbd1535-bc83-4900-ad7d-5282b5b93143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "y: [0 1 0 0 1 1 1 1 1 1]\n",
      "intercept: [-1.51632619]\n",
      "coef: [[0.703457]]\n",
      "p_pred: [[0.81999686 0.18000314]\n",
      " [0.69272057 0.30727943]\n",
      " [0.52732579 0.47267421]\n",
      " [0.35570732 0.64429268]\n",
      " [0.21458576 0.78541424]\n",
      " [0.11910229 0.88089771]\n",
      " [0.06271329 0.93728671]\n",
      " [0.03205032 0.96794968]\n",
      " [0.0161218  0.9838782 ]\n",
      " [0.00804372 0.99195628]]\n",
      "y_pred: [0 0 0 1 1 1 1 1 1 1]\n",
      "score_: 0.8\n",
      "conf_m: [[2 1]\n",
      " [1 6]]\n",
      "report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.76      0.76      0.76        10\n",
      "weighted avg       0.80      0.80      0.80        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('x:', x)\n",
    "print('y:', y)\n",
    "print('intercept:', model.intercept_)\n",
    "print('coef:', model.coef_)\n",
    "print('p_pred:', p_pred)\n",
    "print('y_pred:', y_pred)\n",
    "print('score_:', score_)\n",
    "print('conf_m:', conf_m)\n",
    "print('report:', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CRPgzmJAP9p"
   },
   "source": [
    "# **Partie II : Classification Binaire**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifx0Fkf3QfMe"
   },
   "source": [
    "L'objectif de l'ensemble de données \"**diabetes.csv**\" est de prédire, sur la base de mesures diagnostiques, si un patient **souffre de diabète ou pas**.\n",
    "\n",
    "Ce dataset contient les caractéristiques suivants\n",
    "\n",
    "**Grossesses**: Nombre de fois enceintes.\n",
    "\n",
    "**Glucose**: concentration plasmatique de glucose à 2 heures lors d'un test oral de tolérance au glucose.\n",
    "\n",
    "**Pression artérielle** : tension artérielle diastolique (mm Hg).\n",
    "\n",
    "**Épaisseur de la peau** : épaisseur du pli cutané du triceps (mm).\n",
    "\n",
    "**Insuline** : insuline sérique de 2 heures (mu U/ml).\n",
    "\n",
    "**IMC** : Indice de masse corporelle (poids en kg/(taille en m)^2).\n",
    "\n",
    "**DiabetesPedigreeFunction** : fonction généalogique du diabète.\n",
    "\n",
    "**Âge** : Âge (ans).\n",
    "\n",
    "**Résultat** : variable de classe (0 ou 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFizXutMLhX1"
   },
   "source": [
    "### **Questions :**\n",
    "\n",
    "Étape 1 : Importer et afficher et explorer l'ensemble de données \"**diabetes.csv**\"\n",
    "\n",
    "Étape 2 : Créer dépendante d'une variable indépendante et stockée sur les variables X et Y.\n",
    "\n",
    "Étape 3 : Transformer les chaînes en entier.\n",
    "\n",
    "Étape 4 : Divisez les données en ensembles d'entrainement et de test.\n",
    "\n",
    "Étape 5 : Définir l'algorithme de régression logistique.\n",
    "\n",
    "Étape 6 :Tester les données de test en utilisant votre modèle.\n",
    "\n",
    "Étape 7 : Évaluation du modèle.\n",
    "\n",
    "Étape 8 : Prédire avec de nouvelles valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wlRBxy0D99y",
    "outputId": "cefe284a-c332-46d5-8dd8-cb6ab624d608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "None\n",
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
      "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
      "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
      "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
      "\n",
      "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
      "count  768.000000                768.000000  768.000000  768.000000  \n",
      "mean    31.992578                  0.471876   33.240885    0.348958  \n",
      "std      7.884160                  0.331329   11.760232    0.476951  \n",
      "min      0.000000                  0.078000   21.000000    0.000000  \n",
      "25%     27.300000                  0.243750   24.000000    0.000000  \n",
      "50%     32.000000                  0.372500   29.000000    0.000000  \n",
      "75%     36.600000                  0.626250   41.000000    1.000000  \n",
      "max     67.100000                  2.420000   81.000000    1.000000  \n",
      "(614, 8) (154, 8) (614,) (154,)\n",
      "Accuracy: 0.7467532467532467\n",
      "Confusion Matrix:\n",
      "[[78 21]\n",
      " [18 37]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80        99\n",
      "           1       0.64      0.67      0.65        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.73      0.73       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "Prediction for the new data: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Étape 1 : Importer et afficher et explorer l'ensemble de données \"diabetes.csv\"\n",
    "# On utilise pandas pour lire le fichier CSV et afficher les premières lignes et des informations générales sur les données.\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "print(data.head())  # Afficher les 5 premières lignes\n",
    "print(data.info())  # Informations sur les types de données et les valeurs manquantes\n",
    "print(data.describe())  # Statistiques descriptives des colonnes numériques\n",
    "\n",
    "# Étape 2 : Créer les variables dépendante et indépendante (X et Y)\n",
    "# X contient toutes les colonnes sauf 'Outcome' (variable indépendante)\n",
    "# Y contient uniquement la colonne 'Outcome' (variable dépendante)\n",
    "X = data.drop('Outcome', axis=1)\n",
    "Y = data['Outcome']\n",
    "\n",
    "# Étape 4 : Diviser les données en ensembles d'entraînement et de test\n",
    "# On divise les données en deux ensembles : 80% pour l'entraînement et 20% pour le test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)  # Afficher les dimensions des ensembles\n",
    "\n",
    "# Étape 5 : Définir l'algorithme de régression logistique\n",
    "# On initialise le modèle de régression logistique avec un maximum de 200 itérations pour la convergence\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, Y_train)  # Entraîner le modèle avec les données d'entraînement\n",
    "\n",
    "# Étape 6 : Tester les données de test en utilisant votre modèle\n",
    "# On utilise le modèle entraîné pour prédire les résultats sur l'ensemble de test\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Étape 7 : Évaluation du modèle\n",
    "# Calculer et afficher la précision du modèle\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Afficher la matrice de confusion pour voir les prédictions correctes et incorrectes\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Afficher le rapport de classification pour plus de détails sur la performance du modèle\n",
    "class_report = classification_report(Y_test, Y_pred)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "# Étape 8 : Prédire avec de nouvelles valeurs (corrigé)\n",
    "# On crée un DataFrame pour une nouvelle observation avec les mêmes caractéristiques que le jeu de données d'origine\n",
    "new_data = pd.DataFrame([[2, 130, 80, 30, 0, 32.0, 0.8, 25]], \n",
    "                        columns=['Pregnancies', 'Glucose', 'BloodPressure', \n",
    "                                 'SkinThickness', 'Insulin', 'BMI', \n",
    "                                 'DiabetesPedigreeFunction', 'Age'])\n",
    "# Prédire l'issue pour la nouvelle observation\n",
    "new_prediction = model.predict(new_data)\n",
    "print(f'Prediction for the new data: {new_prediction[0]}')  # Afficher la prédiction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3Zbjz_AAZ5l"
   },
   "source": [
    "# **Partie II : Classification Multi-Classe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1NijNx4OpVg"
   },
   "source": [
    "Pour cette partie, on utilisera le **dataset IRIS**. Ce dernier est une base de données regroupant les caractéristiques de **trois espèces de fleurs d’Iris, à savoir Setosa, Versicolour et Virginica**. Chaque ligne de ce jeu de données est une observation des caractéristiques d’une fleur d’Iris. Ce dataset décrit les espèces d’Iris par quatre propriétés : longueur et largeur de sépales ainsi que longueur et largeur de pétales. La base de données comporte 150 observations (50 observations par espèce)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSTbiW8UMiPt"
   },
   "source": [
    "### **Questions :**\n",
    "\n",
    "Étape 1 : Importer, afficher et explorer l'ensemble de données \"**iris.csv**\"\n",
    "\n",
    "Étape 2 : Créer dépendante d'une variable indépendante et stockée sur les variables X et Y.\n",
    "\n",
    "Étape 3 : Transformer les chaînes en entier.\n",
    "\n",
    "Étape 4 : Divisez les données en ensembles d'entrainement et de test.\n",
    "\n",
    "Étape 5 : Définir l'algorithme de régression logistique.\n",
    "\n",
    "Étape 6 :Tester les données de test en utilisant votre modèle.\n",
    "\n",
    "Étape 7 : Évaluation du modèle.\n",
    "\n",
    "Étape 8 : Prédire avec de nouvelles valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P8PUWA4oTlBB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal.length  sepal.width  petal.length  petal.width variety\n",
      "0           5.1          3.5           1.4          0.2  Setosa\n",
      "1           4.9          3.0           1.4          0.2  Setosa\n",
      "2           4.7          3.2           1.3          0.2  Setosa\n",
      "3           4.6          3.1           1.5          0.2  Setosa\n",
      "4           5.0          3.6           1.4          0.2  Setosa\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal.length  150 non-null    float64\n",
      " 1   sepal.width   150 non-null    float64\n",
      " 2   petal.length  150 non-null    float64\n",
      " 3   petal.width   150 non-null    float64\n",
      " 4   variety       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n",
      "       sepal.length  sepal.width  petal.length  petal.width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.057333      3.758000     1.199333\n",
      "std        0.828066     0.435866      1.765298     0.762238\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n",
      "(120, 4) (30, 4) (120,) (30,)\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Prediction for the new data: Setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Étape 1 : Importer, afficher et explorer l'ensemble de données \"iris.csv\"\n",
    "# On utilise pandas pour lire le fichier CSV et afficher les premières lignes et des informations générales sur les données.\n",
    "data = pd.read_csv('iris.csv')\n",
    "print(data.head())  # Afficher les 5 premières lignes du jeu de données\n",
    "print(data.info())  # Informations sur les types de données et les valeurs manquantes\n",
    "print(data.describe())  # Statistiques descriptives des colonnes numériques\n",
    "\n",
    "# Étape 2 : Créer les variables dépendante et indépendante (X et Y)\n",
    "# X contient toutes les colonnes sauf 'variety' (variable indépendante)\n",
    "# Y contient uniquement la colonne 'variety' (variable dépendante)\n",
    "X = data.drop('variety', axis=1)\n",
    "Y = data['variety']\n",
    "\n",
    "# Étape 3 : Transformer les chaînes en entier\n",
    "# On utilise un encodeur de labels pour transformer les noms de variété en entiers\n",
    "label_encoder = LabelEncoder()\n",
    "Y_encoded = label_encoder.fit_transform(Y)\n",
    "\n",
    "# Étape 4 : Diviser les données en ensembles d'entraînement et de test\n",
    "# On divise les données en deux ensembles : 80% pour l'entraînement et 20% pour le test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_encoded, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)  # Afficher les dimensions des ensembles\n",
    "\n",
    "# Étape 5 : Définir l'algorithme de régression logistique\n",
    "# On initialise le modèle de régression logistique avec un maximum de 200 itérations pour la convergence\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, Y_train)  # Entraîner le modèle avec les données d'entraînement\n",
    "\n",
    "# Étape 6 : Tester les données de test en utilisant votre modèle\n",
    "# On utilise le modèle entraîné pour prédire les résultats sur l'ensemble de test\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Étape 7 : Évaluation du modèle\n",
    "# Calculer et afficher la précision du modèle\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Afficher la matrice de confusion pour voir les prédictions correctes et incorrectes\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Afficher le rapport de classification pour plus de détails sur la performance du modèle\n",
    "class_report = classification_report(Y_test, Y_pred)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "# Étape 8 : Prédire avec de nouvelles valeurs\n",
    "# On crée un DataFrame pour une nouvelle observation avec les mêmes caractéristiques que le jeu de données d'origine\n",
    "new_data = pd.DataFrame([[5.1, 3.5, 1.4, 0.2]], \n",
    "                        columns=['sepal.length', 'sepal.width', 'petal.length', 'petal.width'])\n",
    "# Prédire l'issue pour la nouvelle observation\n",
    "new_prediction = model.predict(new_data)\n",
    "# Transformer la prédiction en nom de variété\n",
    "predicted_class = label_encoder.inverse_transform(new_prediction)\n",
    "print(f'Prediction for the new data: {predicted_class[0]}')  # Afficher la prédiction\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
